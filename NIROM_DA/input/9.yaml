
# 'cae' mode for training Autoencoder, 'lstm' mode for training lstm after autoencoder,
# 'pod' mode for training lstm based on POD, 'caeTest' mode for testing autoencoder,
# 'lstmTest' mode for testing AE-LSTM, and 'podTest' mode for testing POD-LSTM
mode : 'lstmTest'  #   ae, aeTest, lstm, lstmTest, pod, podTest, podAE, podAEtest
var : 'theta'         # Psi for modeling streamfunction and Temperature for modeling temperature      Psi     Temperature

# The entire data set can be larger than training and test set.
# Here I can choose a range for training set and another range for test set.
# The real times may be one time step larger or smaller than the selected times.
trainStartTime : 0      # training starts from trainStartTime
trainEndTime : 175        # training ends at trainEndTime
testStartTime : 120       # test starts from testStartTime
testEndTime : 200         # test ends at testEndTime
figTimeTest : [195, 198]  # Choosing some times to plot the resutls

timeStep : 0.5            # afte discarding in the FOM run

POD-AE:

  podContent : False  # True  False
  podModeContent : 99

  epochsCAE : 5000
  batchSizeCAE : 8
  LrateCAE : 1e-5
  validationAE : 0.2
  AEmode : 4
  PODmode : 28        # 2e6 -> 8, 9e6 -> 28, 1e7 -> 45
  px : 4
  py : 1
  numChannel : 1
  sn : 1
  cae_seed : 43
  encoderDenseMLP : [32, 16, 8]   # 1e7 -> [128, 64, 32, 16]


  epochsLSTM : 300       # number of epochs  t:0.01 400 300      2e6 -> 180, 9e6 -> 1000
  batchSizeLSTM : 64     # batch size
  LrateLSTM : 5e-3        # learning rate
  validationLSTM : 0.2
  windowSize : 10          # window size or look back size
  timeScale : 1          # scaling time step or number of snapshots. the larger timeScale the less snapshots
  lstm_seed : 43            #
  lx : [6.4, 8.0]          # probe location on x direction for temperature
  ly : [0.4, 0.6]           # probe location on y direction for temperature
  #lx : [4, 5.8]          # for psi
  #ly : [1.2, 2.8]           # for psi


#Data Assimilation Input
DA:

  n_types : [1, 2, 1]   # [n_act, n_init, n_opt]
  nBlocks : 2
  numLayer : [20, 20]
  numLayerA : [20]

  #act_dict : {1:'tanh',2:'relu',3:tf.keras.layers.LeakyReLU(alpha=0.1)}
  #init_dict : {1:'uniform',2:'glorot_normal',3:'random_normal'}
  #opt_dict : {1:'adam',2:'rmsprop',3:'SGD',4:'Adadelta',5:'Adamax'}
